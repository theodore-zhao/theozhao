<!DOCTYPE html>
<html lang="en-US">
  <head>
    <title>Theodore (Zhengde) Zhao' Homepage</title>

    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="Welcome to Theodore's Homepage!">
    
    <meta name="keywords" content="Theodore Zhao">
    
    <meta name="google-site-verification" content="PknclP-8ZpqaPE9FxpizH42IUFboq9x0w6YlWA4gBzs" />
    
    <link rel="canonical" href="https://minimal-light-theme.yliu.me/"/>
    

    <link rel="icon" media="(prefers-color-scheme:dark)" href="./assets/img/UWlogo.PNG" type="image/png" />
    <link rel="icon" media="(prefers-color-scheme:light)" href="./assets/img/UWlogo.PNG" type="image/png" />
    <script src="./assets/js/favicon-switcher.js" type="application/javascript"></script>

    <link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin=anonymous>
    <link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css integrity="sha256-+N4/V/SbAFiW1MPBCXnfnP9QSN3+Keu+NlB+0ev/YKQ=" crossorigin=anonymous>

    
    <link rel="stylesheet" href="./assets/css/style-no-dark-mode.css">
    <link rel="stylesheet" href="./assets/css/publications-no-dark-mode.css">
    

  </head>

  <!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-XX46HFG7X5"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-XX46HFG7X5');
</script>
  
  <body>
    <div class="wrapper">
    <header>
                
        <a class="image avatar"><img src="./assets/img/IMG_8207.JPG" alt="avatar" /></a>
        

        <h1>Theodore Zhao</h1>
        <h2 style="font-size: 1rem; margin-top: -20px; color: #888">Zhengde Zhao ËµµÊ≠£Âæ∑</h2>

        
        <position style="font-size:1.10rem;">Senior Applied Scientist</position><br>
        
        <affiliation style="font-size:1.10rem;">
          <a href="https://www.microsoft.com/en-us/" target="_blank" rel="noopener">Microsoft</a>
        </affiliation>
        
        <br>
        <location>Redmond, WA, USA</location>
        <br>
        
        
        <br>
        <div class="social-icons">
          <a href="mailto:tedzh17@gmail.com" target="_blank" rel="noopener" class="social-link">
            <i class="fas fa-envelope fa-lg"></i>
            <span>Email</span>
          </a>
          <a href="https://www.linkedin.com/in/zhengde-theodore-zhao/" target="_blank" rel="noopener" class="social-link">
            <i class="fab fa-linkedin fa-lg"></i>
            <span>LinkedIn</span>
          </a>
          <a href="https://scholar.google.com/citations?hl=zh-TW&user=Ftyui_wAAAAJ&view_op=list_works" target="_blank" rel="noopener" class="social-link">
            <i class="ai ai-google-scholar fa-lg"></i>
            <span>Google Scholar</span>
          </a>
          <a href="https://x.com/IceBubble217" target="_blank" rel="noopener" class="social-link">
            <i class="fab fa-twitter fa-lg"></i>
            <span>Twitter</span>
          </a>
        </div>
        
      
      </header>
      <section>
        <div class="about-me-section">
          <h2 id="about-me">About Me</h2>
          <!--Introducation! Part -->
          <p>I am a Senior Applied Scientist at <a href="https://www.microsoft.com/" target="_blank" rel="noopener">Microsoft</a> developing on multimodal models. I received my PhD and Master degrees in Applied Mathematics from <a href="https://www.washington.edu/" target="_blank" rel="noopener">University of Washington </a>, advised by <a href="https://sites.google.com/site/timleungresearch/" target="_blank" rel="noopener">Prof. Tim Leung</a>. I also worked at Microsoft, Harborview Medical Center, Rotella Capital Management, and Parametric as an Intern. I received my Bachelor degree in Physics from <a href="https://www.fudan.edu.cn/en/" target="_blank" rel="noopener">Fudan University</a> in Shanghai, China.</p>
          My current research interest broadly covers:
          <ul>
            <li>Computer Visoin: Self-supervised Learning, Unified Representation, Fine-grained Understanding.</li>
            <li>Multimodal Modelling: Multimodal Alignment, Vision-Language Models, Promptable Segmentation.</li>
            <li>General Machine Learning: Reinforcement Learning, Pareto Optimization, Multi-objective Learning.</li>
          </ul>
          <p>Recently, I am particularly interested in learning generic intelligence from the vision format (images, videos) and welcome any discussion/collaboration!</p>
          
        </div>

        <div class="news-section">
          <h2 id="news">News</h2>
          <ul>
            <!-- CheckÔºÅÔºÅ  -->
            <li><strong>[Jun. 2025]</strong> The extension of BiomedParse to 3D images won the first place in <a href="https://www.codabench.org/competitions/5651/#/pages-tab" target="_blank" rel="noopener">CVPR 2025: Foundation Models for Text-guided 3D Biomedical Image Segmentation Challenge</a>! </li>
            <li><strong>[Mar. 2025]</strong> <a href="https://openaccess.thecvf.com/content/CVPR2025/papers/Zhao_Boltzmann_Attention_Sampling_for_Image_Analysis_with_Small_Objects_CVPR_2025_paper.pdf" target="_blank" rel="noopener">BoltzFormer</a> is accepted at CVPR 2025! See you in Nashville! </li>
            <li><strong>[Nov. 2024]</strong> <a href="https://www.nature.com/articles/s41592-024-02499-w" target="_blank" rel="noopener">BiomedParse</a> is in Nature Methods! We are also releasing the <a href="https://github.com/microsoft/BiomedParse" target="_blank" rel="noopener">code</a>, <a href="https://huggingface.co/microsoft/BiomedParse" target="_blank" rel="noopener">model</a>, and a million scale text promptable medical image segmentation <a href="https://huggingface.co/datasets/microsoft/BiomedParseData" target="_blank" rel="noopener">dataset</a>. </li>
            <li><strong>[May. 2024]</strong> Proud to lead the <a href="https://microsoft.github.io/BiomedParse/" target="_blank" rel="noopener">BiomedPrase</a> project. We presented a foundation model for joint segmentation, detection and recognition of biomedical objects across nine modalities. Various medical image analysis tasks are unified with natural language prompting. </li>
            <li><strong>[May. 2024]</strong> Our paper on <a href="https://aclanthology.org/2024.acl-long.566/">Error Detection</a> is accepted by <a href="https://2024.aclweb.org/">ACL 2024</a>. See you in Bangkok!</li>
            <li><strong>[April. 2024]</strong> I am giving a talk at <a href="https://ww2.amstat.org/meetings/jsm/2024/" target="_blank" rel="noopener">2024 Joint Statistical Meetings</a> on 08/05/2024 in Portland.</li>
          </ul>
        </div>

        <div class="publications">
          <h2 id="publications">Recent Works</h2>
          <div class="publications">
            <ol class="bibliography">

              <li>
                <div class="pub-row row">
                  <div class="col-sm-3 abbr">
                    <img src="./assets/img/3D.png" class="teaser img-fluid z-depth-1" alt="Publication Teaser Image">
                  </div>
                  <div class="col-sm-9">
                    <div class="title"><a href="https://openreview.net/pdf?id=WNhWdr9mCB">BiomedParse-V: Scaling Foundation Model for Universal Text-guided Volumetric Biomedical Image Segmentation</a></div>
                    <div class="author"><strong>Theodore Zhao</strong>, Ho Hin Lee, Alberto Santamaria-Pang, Noel C. Codella, Sid Kiblawi, Yu Gu, Yu Fang, Wen Xuan Teng, Naiteek Sangani, Ivan Tarapov, Matthew P. Lungren, Matthias Blondeel, Tristan Naumann, Naoto Usuyama, Sheng Wang, Paul Vozila, Hoifung Poon, Mu Wei^</div>
                    <div class="periodical">
                      <em><u><strong>In Review, </strong></u>2025 </em>
                    <div class="links ml-2">
                     <a href="https://openreview.net/pdf?id=WNhWdr9mCB" class="btn btn-sm z-depth-0" role="button" target="_blank">[PAPER]</a>
                     <a href="https://github.com/microsoft/BiomedParse" class="btn btn-sm z-depth-0" role="button" target="_blank">[CODE]</a>
                    </div> 
                  
                    </div>
                    <!-- <div class="description mt-2">
                      <em>We used Boltzmann sampling in the attention mechanism with temperature annealing, and achieved superior performance in aligning small regions in the image with language instructions.</em>
                    </div> -->
                  </div>
                </div>
              </li>

              
              <li>
                <div class="pub-row row">
                  <div class="col-sm-3 abbr">
                    <img src="./assets/img/Attention.png" class="teaser img-fluid z-depth-1" alt="Publication Teaser Image">
                  </div>
                  <div class="col-sm-9">
                    <div class="title"><a href="https://openaccess.thecvf.com/content/CVPR2025/papers/Zhao_Boltzmann_Attention_Sampling_for_Image_Analysis_with_Small_Objects_CVPR_2025_paper.pdf">Boltzmann Attention Sampling for Image Analysis with Small Objects</a></div>
                    <div class="author"><strong>Theodore Zhao</strong>*, Sid Kiblawi*, Naoto Usuyama, Hohin Lee, J Samuel Preston, Hoifung Poon, Mu Wei^</div>
                    <div class="periodical">
                      <em><u><strong>CVPR, </strong></u>2025 </em>
                    <div class="links ml-2">
                     <a href="https://openaccess.thecvf.com/content/CVPR2025/papers/Zhao_Boltzmann_Attention_Sampling_for_Image_Analysis_with_Small_Objects_CVPR_2025_paper.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">[PAPER]</a>
                     <a href="https://aka.ms/boltzformer" class="btn btn-sm z-depth-0" role="button" target="_blank">[CODE]</a>
                    </div> 
                  
                    </div>
                    <!-- <div class="description mt-2">
                      <em>We used Boltzmann sampling in the attention mechanism with temperature annealing, and achieved superior performance in aligning small regions in the image with language instructions.</em>
                    </div> -->
                  </div>
                </div>
              </li>
              
              <li>
                <div class="pub-row row">
                  <div class="col-sm-3 abbr">
                    <img src="./assets/img/BIOMEDPARSE_holsoyka-short.jpg" class="teaser img-fluid z-depth-1" alt="Publication Teaser Image">
                  </div>
                  <div class="col-sm-9">
                    <div class="title"><a href="https://www.nature.com/articles/s41592-024-02499-w">A foundation model for joint segmentation, detection and recognition of biomedical objects across nine modalities</a></div>
                    <div class="author"><strong>Theodore Zhao</strong>*, Yu Gu*, Jianwei Yang, Naoto Usuyama, Ho Hin Lee, Sid Kiblawi, Tristan Naumann, Jianfeng Gao, Angela Crabtree, Jacob Abel, Christine Moung-Wen, Brian Piening, Carlo Bifulco, Mu Wei^, Hoifung Poon^, Sheng Wang^</div>
                    <div class="periodical">
                      <em><strong><u>Nature Methods</u></strong>, 2024</em>
                      <div class="links ml-2">
                        <a href="https://www.nature.com/articles/s41592-024-02499-w" class="btn btn-sm z-depth-0" role="button" target="_blank">[PAPER]</a>
                        <a href="https://microsoft.github.io/BiomedParse/" class="btn btn-sm z-depth-0" role="button" target="_blank">[DEMO]</a>
                       <a href="https://www.microsoft.com/en-us/research/blog/biomedparse-a-foundation-model-for-smarter-all-in-one-biomedical-image-analysis/" class="btn btn-sm z-depth-0" role="button" target="_blank">[BLOG]</a> 
                        <a href="https://github.com/microsoft/BiomedParse" class="btn btn-sm z-depth-0" role="button" target="_blank">[CODE]</a>
                        <a href="https://huggingface.co/microsoft/BiomedParse" class="btn btn-sm z-depth-0" role="button" target="_blank">[MODEL]</a>
                        <a href="https://huggingface.co/datasets/microsoft/BiomedParseData" class="btn btn-sm z-depth-0" role="button" target="_blank">[DATA]</a>
                      </div>
                    </div>
                    <!-- <div class="description mt-2">
                      <em>We propose BiomedParse, a biomedical foundation model that can jointly conduct segmentation, detection and recognition across nine imaging modalities. </em>
                    </div> -->
                  </div>
                </div>
              </li>
              
              <li>
                <div class="pub-row row">
                  <div class="col-sm-3 abbr">
                    <img src="./assets/img/pareto.PNG" class="teaser img-fluid z-depth-1" alt="Publication Teaser Image">
                  </div>
                  <div class="col-sm-9">
                    <div class="title"><a href="https://aclanthology.org/2024.acl-long.566/">Pareto Optimal Learning for Estimating Large Language Model Errors</a></div>
                    <div class="author"><strong>Theodore Zhao</strong>, Mu Wei, J Samuel Preston, Hoifung Poon</div>
                    <div class="periodical">
                      <em><u><strong>ACL, </strong></u>2024 </em>
                    <div class="links ml-2">
                     <a href="https://aclanthology.org/2024.acl-long.566.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">[PDF]</a>
                    </div> 
                  
                    <!-- </div>
                    <div class="description mt-2">
                      <em>We utilized Pareto optimal learning to estimate response error and increase the performance, surpassing state-of-the-art task specific models.</em>
                    </div> -->
                  </div>
                </div>
              </li>
              
              
              <!-- <li>
                <div class="pub-row row">
                  <div class="col-sm-3 abbr">
                    <img src="./assets/img/survey.PNG" class="teaser img-fluid z-depth-1" alt="Publication Teaser Image">
                  </div>
                  <div class="col-sm-9">
                    <div class="title"><a href="https://arxiv.org/abs/2401.07654">Foundation Models for Biomedical Image Segmentation: A Survey</a></div>
                    <div class="author">Ho Hin Lee*, Yu Gu*, <strong>Theodore Zhao, </strong>Yanbo Xu, Jianwei Yang, Naoto Usuyama, Cliff Wong, Mu Wei, Bennett A Landman, Yuankai Huo, Alberto Santamaria-Pang, Hoifung Poon</div>
                    <div class="periodical">
                      <em><strong><u>Preprint</strong></u>, 2024</em>
                      <div class="links ml-2">
                        <a href="https://arxiv.org/pdf/2401.07654" class="btn btn-sm z-depth-0" role="button" target="_blank">[PDF]</a>
                      </div>
                    </div>
                    <!-- <div class="description mt-2">
                      <em>We examine the adaptations and integrations of SAM necessary to address longstanding clinical challenges, in the context of 33 open datasets covered in our analysis.</em>
                    </div> -->
                  </div>
                </div>
              </li> -->
        
        </ol>
          </div>
        </div>


        <div class="publications">
          <h2 id="publications">Previous Works (during PhD)</h2>
          <div class="publications">
            <ol class="bibliography">
              
              <li>
                <div class="pub-row row">
                  <div class="col-sm-3 abbr">
                    <img src="./assets/img/MS_Corr.png" class="teaser img-fluid z-depth-1" alt="Publication Teaser Image">
                  </div>
                  <div class="col-sm-9">
                    <div class="title"><a href="https://www.mdpi.com/2227-7390/12/6/864">A Noisy Fractional Brownian Motion Model for Multiscale Correlation Analysis of High-Frequency Prices</a></div>
                    <div class="author">Tim Leung*, <strong>Theodore Zhao*</strong></div>
                    <div class="periodical">
                      <em><strong><u>Mathematics</strong></u>, 2024</em>
                    <!--  <div class="links ml-2">
                        <a href="https://www.mdpi.com/2227-7390/12/6/864" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
                      </div> -->
                    </div>
                  <!-- <div class="description mt-2">
                      <em>We analyze the multiscale behaviors of high-frequency intraday prices, with a focus on how asset prices are correlated over different timescales. </em>
                    </div>  -->
                  </div>
                </div>
              </li>
              
              <li>
                <div class="pub-row row">
                  <div class="col-sm-3 abbr">
                    <img src="./assets/img//thelancet.PNG" class="teaser img-fluid z-depth-1" alt="Publication Teaser Image">
                  </div>
                  <div class="col-sm-9">
                    <div class="title"><a href="https://www.thelancet.com/journals/lanhiv/article/PIIS2352-3018(22)00254-5/abstract">Fee for home delivery and monitoring of antiretroviral therapy for HIV infection compared with standard clinic-based services in South Africa: a randomised controlled trial</a></div>
                    <div class="author">Ruanne V Barnabas, Adam A Szpiro, Xolani Ntinga, Melissa Latigo Mugambi, Heidi van Rooyen, Andrew Bruce, Philip Joseph, Thulani Ngubane, Meighan L Krows, Torin T Schaafsma, <strong>Theodore Zhao</strong>, Frank Tanser, Jared M Baeten, Connie Celum, Alastair van Heerden, Siyabonga Nkala</div>
                    <div class="periodical">
                      <em><strong><u>The Lancet HIV</strong></u>, 2022</em>
                   <!--   <div class="links ml-2">
                        <a href="https://www.thelancet.com/journals/lanhiv/article/PIIS2352-3018(22)00254-5/abstract" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
                      </div> -->
                    </div>
                  <div class="description mt-2">
                      <em>We conducted a randomised trial, the Deliver Health Study, of a fee for home delivery of ART compared d with free clinic ART delivery in South Africa.</em>
                   </div>
                 </div>
               </div>
              </li>
              <li>
                <div class="pub-row row">
                  <div class="col-sm-3 abbr">
                    <img src="./assets/img/MLMathmatics.PNG" class="teaser img-fluid z-depth-1" alt="Publication Teaser Image">
                  </div>
                  <div class="col-sm-9">
                    <div class="title"><a href="https://onlinelibrary.wiley.com/doi/abs/10.1002/asmb.2625">Financial time series analysis and forecasting with Hilbert‚ÄìHuang transform feature generation and machine learning</a>
                      <div class="author">Tim Leung*, <strong>Theodore Zhao*</strong></div>
                    <div class="periodical">
                      <em><strong><u>Applied Stochastic Models in Business and Industry</strong></u>, 2021</em>
                      <div class="links ml-2">
                        <a href="https://arxiv.org/pdf/2105.10871" class="btn btn-sm z-depth-0" role="button" target="_blank">[PDF]</a>
                      </div>
                    </div>
                    <div class="description mt-2">
                      <em>We present the method of complementary ensemble empirical mode decomposition (CEEMD) and Hilbert-Huang transform (HHT) for analyzing nonstation financial time series.  
            </ol>
          </div>
        </div>
  <!-- Fun -->  
        <div class="fun-section">
          <h2 id="fun">Misc</h2>
          <div class="fun-section">
            <h4 id="fun">In my free time, I love stargazing. I also started making my own music recently.</h4>
            <p id="fun">  Here are some of my music ‚Äî Just a heads-up, you'll hear real SOUND when you hit ‚Äúplay‚Äù! üéµ üéß</p>
            <ul class="music-list">
              <li class="music-item">
                <p><strong> For Nora: Entanglement</strong></p>
                <audio id="audio1" src="./assets/music/SnowDance.m4a"></audio>
                <button class="audio-btn" onclick="document.getElementById('audio1').play()">
                  <i class="fas fa-play"></i> <span>Play</span>
                </button>
                <button class="audio-btn" onclick="document.getElementById('audio1').pause()">
                  <i class="fas fa-pause"></i> <span>Pause</span>
                </button>
              </li>
            </li>
            <li class="music-item">
              <p><strong>For Parents' 30th Anniversary: Pearl Waltz</strong></p>
              <audio id="audio3" src="./assets/music/Waltz for 30th Anniversary.m4a"></audio>
              <button class="audio-btn" onclick="document.getElementById('audio3').play()">
                <i class="fas fa-play"></i> <span>Play</span>
              </button>
              <button class="audio-btn" onclick="document.getElementById('audio3').pause()">
                <i class="fas fa-pause"></i> <span>Pause</span>
              </button>
            </li>
              <li class="music-item">
                <p><strong>For Dad: √Ä La Recherche Du Temps Perdu</strong></p>
                <audio id="audio2" src="./assets/music/Fordad.m4a"></audio>
                <button class="audio-btn" onclick="document.getElementById('audio2').play()">
                  <i class="fas fa-play"></i> <span>Play</span>
                </button>
                <button class="audio-btn" onclick="document.getElementById('audio2').pause()">
                  <i class="fas fa-pause"></i> <span>Pause</span>
                </button>
              </li>
              <li class="music-item">
                <p><strong>For Mom: Sunshine in the Winter</strong></p>
                <audio id="audio4" src="./assets/music/Formom.m4a"></audio>
                <button class="audio-btn" onclick="document.getElementById('audio4').play()">
                  <i class="fas fa-play"></i> <span>Play</span>
                </button>
                <button class="audio-btn" onclick="document.getElementById('audio4').pause()">
                  <i class="fas fa-pause"></i> <span>Pause</span>
                </button>
              </li>
           
            
            </ul>
          </div>
        </div>
    
        <h3 id="collaborations" > <u>If my research/music interests you, <a href="mailto:tedzh17@gmail.com">send me an email! </a>I'm always open to collaborations and discussions.üç∫</u>
        <h3>
    
        <!-- Add Font Awesome library if not already included -->
        <div>
          <script src="https://kit.fontawesome.com/a076d05399.js" crossorigin="anonymous"></script>
    
    
      </section>
       
    <!-- <p id="footer"><small>¬© 2024 Theodore Zhao. <a href="https://minimal-light-theme.yliu.me/">Website Template</a></small> </p> -->
  <!-- Map -->     
<!--    <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=196&t=tt&d=HA7UQZgJrYBsaQ-gV1hZCcq0aZuaUShYQMxJK0hdPuY'></script> -->
   <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=196&t=tt&d=HA7UQZgJrYBsaQ-gV1hZCcq0aZuaUShYQMxJK0hdPuY'></script>       
          <footer style="text-align: center; padding: 20px; font-size: 0.9rem; color: #888;">
  <p>¬© 2024 Theodore Zhao. <a href="https://minimal-light-theme.yliu.me/" target="_blank" rel="noopener">Website Template</a></p>
</footer>

  </body>
  </html>
  
